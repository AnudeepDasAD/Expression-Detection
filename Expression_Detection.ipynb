{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expression_Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnudeepDasAD/Expression-Detection/blob/master/Expression_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m80oEGzkbPOD",
        "colab_type": "code",
        "outputId": "6ac45340-16cb-4567-c5c4-83a121f0e3f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "source": [
        "#Need to collect images first\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "#PIL is the Python Image Library\n",
        "from keras import regularizers\n",
        "\n",
        "import h5py\n",
        "\n",
        "hf = h5py.File('expression_train.h5', 'r')\n",
        "hr = h5py.File('expression_test.h5', 'r')\n",
        "\n",
        "x_train = hf.get('x_train')\n",
        "y_labels = hf.get('y_labels')\n",
        "\n",
        "x_test = hr.get('x_test')\n",
        "y_test = hr.get('y_test')\n",
        "\n",
        "labels = [\"Neutral\", \"Anger\", \"Contempt\", \"Disgust\", \"Fear\", \"Happy\", \"Sadness\", \"Surprise\"]\n",
        "\n",
        "gpu_options = tf.GPUOptions(allow_growth=True)\n",
        "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "'''\n",
        "#Actual folder names\n",
        "labels_directory = \"Emotion\"\n",
        "\n",
        "images_directory= \"cohn-kanade-images\"\n",
        "\n",
        "#label will be the folder's name\n",
        "\n",
        "current_id=0\n",
        "label_ids = {\"Neutral\":0, \"Anger\":1, \"Contempt\":2, \"Disgust\":3, \"Fear\":4, \"Happy\":5, \"Sadness\":6, \"Surprise\": 7}\n",
        "\n",
        "\n",
        "#Will hold the paths to the labels because the file structure for the images is very similar\n",
        "paths = []\n",
        "\n",
        "#Walking through the directory and assembling all of the y-values\n",
        "for root, dirs, files in os.walk(labels_directory):\n",
        "\t#print(\"In forst loop\")\n",
        "\tfor file in files:\n",
        "\t\tif file.endswith(\"txt\"):\n",
        "\t\t\tpath = os.path.join(root, file)\n",
        "\t\t\tpaths.append(path)\n",
        "\t\t\t#f = open(str(path), \"r\")\n",
        "\t\t\twith open(str(path)) as f:\n",
        "\t\t\t\tfor line in f:\n",
        "\t\t\t\t\tline = line.strip()\n",
        "\t\t\t\t\t#Line is not empty\n",
        "\t\t\t\t\tif line:\n",
        "\t\t\t\t\t\t#print(int(float(line))) It works!\n",
        "\t\t\t\t\t\tid_ = int(float(line))\n",
        "\t\t\t\t\t\ty_labels.append(id_)\n",
        "\t\t\t\t\t\t#print(id_)\n",
        "\n",
        "#Assembling the images and x_train\n",
        "\n",
        "index = 0\n",
        "for path in paths:\n",
        "\t#The first part of the relative path changes\n",
        "\tpath = path.replace(labels_directory, images_directory)\n",
        "\n",
        "\t#The name of \n",
        "\tpath = path.replace(\"_emotion.txt\", \".png\")\n",
        "\n",
        "\timage_array = Image.open(path)\n",
        "\t#pil_image.resize((275,275), Image.ANTIALIAS)\n",
        "\t#Convert the image into a numpy array\n",
        "  \n",
        "\timage_array = np.array(image_array, \"uint8\")\n",
        "\n",
        "\n",
        "\t#print(image_array.shape)\n",
        "\n",
        "\t#Ensuring all have the same shape   \n",
        "\tif image_array.shape != (490,640):\n",
        "\t\ty_labels.pop(index)\n",
        "\t\tcontinue\n",
        "        \n",
        "\tx_train.append(image_array)\n",
        "\n",
        "\tindex += 1\n",
        "\t\t\n",
        "\n",
        "#print(x_train.shape)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_train = x_train.reshape(-1,490,640,1)\n",
        "\n",
        "'''\n",
        "print(x_train.shape)\n",
        "print(y_labels.shape)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "#Convolutions are filters made to detect certain aspects of images (some edges)\n",
        "   tf.keras.layers.Conv2D(60, kernel_size=(3,3), input_shape=(300,300,1)),\n",
        "    tf.keras.layers.Dense(40, kernel_regularizer=regularizers.l2(0.001), activation=tf.nn.relu, input_shape=(300,300,1)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(50, kernel_size=(3,3), input_shape=(300,300,1)),\n",
        "    #tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.Dense(40, kernel_regularizer=regularizers.l2(0.001), activation=tf.nn.relu, input_shape=(300,300,1)),\n",
        "  \n",
        "    tf.keras.layers.Dense(30, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(8, activation=tf.nn.softmax)\n",
        "\t])\n",
        "\n",
        "#print(len(x_train))\n",
        "#print(len(y_labels))\n",
        "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "history = model.fit(x=x_train, y=y_labels, epochs=10, validation_split=0.1, shuffle=\"batch\")\n",
        "\n",
        "#plt.imshow(x_test[11].reshape(300,300))\n",
        "pred = model.predict(x_train[11].reshape(1,300,300,1))\n",
        "print(labels[np.argmax(pred)])\n",
        "\n",
        "model.evaluate(x=x_test, y=y_test)\n",
        "\n",
        "# Get training and test loss histories\n",
        "training_loss = history.history['loss']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "#length of training loss is total number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, test_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Test Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(261, 300, 300, 1)\n",
            "(261,)\n",
            "Train on 234 samples, validate on 27 samples\n",
            "Epoch 1/10\n",
            "234/234 [==============================] - 7s 32ms/sample - loss: 152.0613 - val_loss: 238.0932\n",
            "Epoch 2/10\n",
            "234/234 [==============================] - 5s 20ms/sample - loss: 81.0447 - val_loss: 142.7365\n",
            "Epoch 3/10\n",
            "234/234 [==============================] - 5s 20ms/sample - loss: 63.9248 - val_loss: 96.2076\n",
            "Epoch 4/10\n",
            "234/234 [==============================] - 5s 20ms/sample - loss: 32.0933 - val_loss: 31.6028\n",
            "Epoch 5/10\n",
            "192/234 [=======================>......] - ETA: 0s - loss: 21.5397"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-5c94a7b1de32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#plt.imshow(x_test[11].reshape(300,300))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}